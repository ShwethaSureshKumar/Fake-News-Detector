# Fake-News-Detector
9th sem IR Package


## Problem Statement
The spread of online misinformation is a major societal challenge. Traditional manual verification is too slow, while simple blacklisting cannot handle constantly evolving claims and newly emerging misinformation. Therefore, an automated and scalable fact-verification mechanism is needed.

## Objective
To design, build, and deploy an automated API system that:
- accepts any news article URL,
- extracts the primary claim in real-time, and
- verifies its authenticity by retrieving and analyzing evidence from the web.

The system returns a verdict based on dynamically collected online evidence.

## System Overview
This project implements a full-stack, automated verification pipeline integrating:

### 1. Browser Extension (Frontend)
- User clicks a button on the extension while reading any news article
- The extension sends the current URL to the backend API

### 2. Flask API Server (Backend)
- Receives the URL from the browser extension
- Runs automated verification steps

## Methodology (Pipeline)

### 1. Information Extraction
- The system scrapes the article text
- Uses TextRank (Graph-based Extractive Summarization)
- Extracts the most central sentence as the main claim

### 2. Evidence Retrieval
- The extracted claim is passed to SerpAPI (Google Search)
- Retrieves top 10 evidence snippets and URLs
- These snippets are used as real-time evidence

### 3. Machine Learning Verdict (Weighted Ensemble Model)
Three independent models contribute scores:

#### Semantic Model (60%)
- spaCy word embeddings
- Measures semantic similarity between claim and evidence

#### Sentiment Model (30%)
- Uses NLTK VADER
- Detects negative sentiment common in debunking articles

#### Source Model (10%)
- Rule-based trust score
- Evaluates the credibility of evidence domains

The final decision is generated by a weighted average of all three scores.

## Output
The weighted score is mapped into:
- VERIFIED (TRUE)
- VERIFIED (FALSE)
- UNVERIFIED

This verdict is sent back to the browser extension in real-time.

## Dataset
This project does not rely on a static dataset.  
Instead, it builds a real-time dataset per request by fetching:
- top 10 organic search results,
- evidence snippets,
- and their URLs.

This avoids scraping entire web pages, ensures higher precision, and reduces noise.

## Metrics

| Metric | Range | Description |
|--------|--------|-------------|
| semantic_score | 0.0 – 1.0 | Semantic similarity between claim and evidence |
| sentiment_score | -1.0 – 1.0 | Detects negative (debunking) sentiment |
| source_score | -1.0 – 1.0 | Domain trustworthiness |

## Technologies Used
- Chrome Extension (JavaScript)
- Python Flask (API)
- spaCy (NLP)
- NLTK VADER (Sentiment Analysis)
- SerpAPI (Google Search API)


